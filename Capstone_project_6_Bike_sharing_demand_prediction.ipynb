{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "35m5QtbWiB9F",
        "nA9Y7ga8ng1Z",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "eqnGgOMiunN7",
        "0wOQAZs5pc--",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "ynDtdhucBFfm",
        "YJ55k-q6phqO",
        "jCtfBBAzFXWL",
        "q29F0dvdveiT",
        "g-ATYxFrGrvw",
        "id1riN9m0vUs",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Seoul Bike Sharing Demand Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "***\n",
        "SAMYAK JAIN\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project emphasises on predicting the hourly demand for rental bikes in urban areas to ensure a stable and efficient supply, thereby reducing user wait times and enhancing the bike-sharing experience. By employing exploratory data analysis (EDA) to understand patterns and relationships and correlations in the data, and employing various regression algorithms such as linear regression, ridge regression, lasso regression, and elastic net regression, we aim to accurately forecast bike demand. The project involves splitting the data into training and test sets, evaluating models using metrics like RMSE, MAE, and R-squared, and tuning hyperparameters for optimal performance. The insights gained will help identify key factors affecting bike demand, such as weather and time of day, leading to recommendations for better bike distribution strategies.At last, this project aims  in making informed decisions to improve the availability and accessibility of rental bikes."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "jxrOwTf-c3JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Data manipulation and numerical operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "# Data visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# machine learning algorithms and preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from scipy import stats\n",
        "from scipy.stats import f_oneway\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For statistical models and tests\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZsOW4BsRFR6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/SeoulBikeData.csv', encoding='unicode_escape')\n",
        "df = dataset.copy()"
      ],
      "metadata": {
        "id": "ZbqUItsfko3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Above dataset have 8760 rows and 14 columns."
      ],
      "metadata": {
        "id": "jQI-YIvtmdNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### According to above information the goven dataset do not have null values."
      ],
      "metadata": {
        "id": "iM_WEhycmnr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_values = df.duplicated().sum()\n",
        "print(\"Number of duplicate values:\", duplicate_values)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the given dataset there is no any duplicate value."
      ],
      "metadata": {
        "id": "JU7VMrKFmxNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values count:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### There is no any missing value in the given dataset."
      ],
      "metadata": {
        "id": "s_GK8m92m7KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary :"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In the given dataset there are 8760 rows and 14 columns and also there is no any null value, duplicate value and missing value."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Date** : Date on which bike rented.\n",
        "* **Rented Bike Count** : Count of Bike Rented.\n",
        "* **Hour** : Hour of the day (0-23).\n",
        "* **Temperature** : Temprature of the day in celcius.\n",
        "* **Humidity** : Humidity of the day in percentage.\n",
        "* **Wind Speed** : Speed of wind in m/s.\n",
        "* **Visibility** : Visibility Measure 10m.\n",
        "* **Dew Point Temprature** : Dew Point Temprature measure in degree celcius.\n",
        "* **Solar radiation** : Solar radiation measure in MJ/m2.\n",
        "* **Rainfall** : Rainfall in mm.\n",
        "* **Snowfall** : Snowfall measure in cm.\n",
        "* **Seasons** : Spring, Summer, Fall, Winter.\n",
        "* **Holidays** : Whether a holiday or not.\n",
        "* **Functional** : Whether a functional day or not."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values using lambda function for each variable.\n",
        "print(df.apply(lambda x: len(x.unique())))"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating function to return all the unique values each categorical colum can have\n",
        "def cat_unique_vals(cat_cols,df):\n",
        "  for col in cat_cols:\n",
        "    print(\"The values that the categorical column\",col,\"can take are:\",df[col].unique())"
      ],
      "metadata": {
        "id": "EwUXFS5zrBi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the possible values importanat and meaningful categorical columns can have.\n",
        "categorical_columns=['Seasons','Holiday']\n",
        "cat_unique_vals(categorical_columns,df)"
      ],
      "metadata": {
        "id": "MIEAKUK5rF6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handelling Null Values**"
      ],
      "metadata": {
        "id": "eqnGgOMiunN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cheking for null values\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "8N4OgBoRuDw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Here we can see no any null value in the given dataset.**"
      ],
      "metadata": {
        "id": "y-G6S5wEuPpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handelling Duplicate Values**"
      ],
      "metadata": {
        "id": "RfETZJt3uvW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Duplicate Values\n",
        "df1.duplicated().sum()"
      ],
      "metadata": {
        "id": "G2dyTIhruYGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The the given dataset we do not have any duplicate value.**"
      ],
      "metadata": {
        "id": "uZmpRd4Fuc44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **The above dataset have 8760 rows and 14 columns.**\n",
        "* **The above dataset do not have duplicate and missing values.**"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Data Vizualization with charts"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### distribution of the 'Rented Bike Count?"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate distribution of the ranted bike count\n",
        "rented_bike_count = df1['Rented Bike Count'].value_counts()\n",
        "print(rented_bike_count)"
      ],
      "metadata": {
        "id": "TwTWKXocxQP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code for rented_bike_count\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df1['Rented Bike Count'], bins=20, kde=True)\n",
        "plt.title('Distribution of Rented Bike Count')\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : A histplot, or histogram plot, is commonly used to visualize the distribution of rented bike counts because it provides a clear representation of how the counts are spread across different ranges."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The right-skewed nature of the graph indicates that the majority of rental instances involve only a few bikes being rented, while there are occasional instances where a significantly higher number of bikes are rented. This suggests that the bulk of the activity, in terms of rental counts, is concentrated towards the lower end of the scale, with progressively fewer instances occurring as the rental counts increase."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3.INSIGHTS"
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The right-skewed rental data suggests focusing on promotions for individual or small group rentals, optimizing bike distribution to match typical demand, and implementing dynamic pricing to balance demand and maximize revenue. However, ignoring the few high-demand instances could lead to missed opportunities and potential customer dissatisfaction during peak times."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 : How does the distribution of 'Rented Bike Count' vary throughout the days in the dataset?"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' column to datetime, handle errors\n",
        "df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaT (parsing errors)\n",
        "data = df1.dropna(subset=['Date'])\n",
        "\n",
        "# Extract 'Date' and 'Rented Bike Count' columns\n",
        "bike_counts_by_date = data[['Date', 'Rented Bike Count']]\n",
        "\n",
        "# Group by day and calculate mean or sum of 'Rented Bike Count'\n",
        "daily_bike_counts = bike_counts_by_date.groupby(bike_counts_by_date['Date'].dt.date)['Rented Bike Count'].sum()\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=daily_bike_counts)\n",
        "plt.title('Distribution of Rented Bike Count Throughout the Days')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Rented Bike Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0_UCImjr7SQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I used line plot because line plot for visualizing the distribution of bike rentals over time aligns well with the nature of the data and the goal of identifying temporal trends and patterns in bike rental demand."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The graph shows that there's a rise in bike rentals during 2018 compared to 2017, with noticeable drops in rentals during 2017. Starting from early 2018, there's a general trend of more variability and peaks in bike rentals. This could suggest that bike rentals became more popular or there were increased marketing efforts around that time."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 : How does 'Temperature(°C)' affect 'Rented Bike Count'?"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the correlation between temprature and rented bike count\n",
        "correlation = df1['Temperature(°C)'].corr(df1['Rented Bike Count'])\n",
        "print(\"Correlation between Temperature and Rented Bike Count:\", correlation)"
      ],
      "metadata": {
        "id": "l_Shkfmu9hwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df1, x='Temperature(°C)', y='Rented Bike Count')\n",
        "plt.title(\"Temperature vs Rented Bike Count\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : A scatter plot is used to visualize the relationship between two variables by plotting individual data points on a Cartesian plane. It helps identify patterns, trends, and correlations between the variables, making it suitable for exploring how changes in one variable (e.g., temperature) affect another (e.g., bike rentals) across different observations."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The scatter plot indicates a positive correlation between temperature and bike rentals, with higher temperatures generally leading to more bike rentals. The rental count increases significantly as temperatures rise up to around 20-25°C, beyond which the rental growth plateaus or slightly decreases. This suggests that bike rental demand is highest in mild to warm weather conditions."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The insights gained from the analysis can indeed have a positive business impact. Understanding the positive correlation between temperature and bike rentals, with a peak demand in mild to warm weather conditions, allows businesses to capitalize on this relationship."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 : How do 'Seasons' affect 'Rented Bike Count'?"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate seasons affect rented bike count\n",
        "seasons_rented_bike_count = df1.groupby('Seasons')['Rented Bike Count'].sum().reset_index()\n",
        "print(seasons_rented_bike_count)"
      ],
      "metadata": {
        "id": "T8HMZ1ry_pN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.barplot(data=seasons_rented_bike_count, x='Seasons', y='Rented Bike Count', palette = 'deep')\n",
        "plt.title(\"Seasons vs Rented Bike Count\")\n",
        "plt.xlabel(\"Seasons\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : According to the graph, the rented bike count is highest in the summer season, followed by autumn and then spring. The rented bike count is lowest in the winter season."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The insights indicating higher bike rentals in summer, autumn, and spring can help businesses optimize resources and marketing efforts during these peak seasons, positively impacting revenue. However, the low rental count in winter could lead to negative growth if not addressed, suggesting a need for strategies to attract customers or diversify offerings during colder months."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 : How does 'Wind speed (m/s)' affect 'Rented Bike Count'?"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rented_bike_count_by_wind_speed = df1.groupby('Wind speed (m/s)')['Rented Bike Count'].sum().reset_index()\n",
        "print(rented_bike_count_by_wind_speed)"
      ],
      "metadata": {
        "id": "kHpGceGTuXJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df1, x='Wind speed (m/s)', y='Rented Bike Count')\n",
        "plt.title(\"Wind speed vs Rented Bike Count\")\n",
        "plt.xlabel(\"Wind speed\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : According to above graph we can see that when the wind speed is low then the rented bike count is hight and when wind speed is maximum then the bike count is less. We can see that between 1-3 m/s wind speed the count is maximum and when the wind speed is above 5 m/s then the count is very very less."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The insights show that bike rentals are highest at low wind speeds (1-3 m/s) and drop significantly at high wind speeds (above 5 m/s). This can help businesses plan better by promoting rentals during favorable wind conditions. However, high wind speeds may lead to fewer rentals, suggesting a need for strategies to maintain demand during such conditions."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 : How do 'Holiday' affect 'Rented Bike Count'?"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute rented bike count by holiday\n",
        "rented_bike_count_by_holiday = df1.groupby('Holiday')['Rented Bike Count'].sum().reset_index()\n",
        "print(rented_bike_count_by_holiday)"
      ],
      "metadata": {
        "id": "nBszFe99v6vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=rented_bike_count_by_holiday, x='Holiday', y='Rented Bike Count', palette='muted')\n",
        "plt.title(\"Holiday vs Rented Bike Count\")\n",
        "plt.xlabel(\"Holiday\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : According to the above graph when there is holiday then the bike count is very less and when there is no holiday then rented bike count is very high."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 : How does visibility ('Visibility (10m)') influence bike rental count?"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute bike rental count by visibility\n",
        "rented_bike_count_by_visibility = df1.groupby('Visibility (10m)')['Rented Bike Count'].sum().reset_index()\n",
        "print(rented_bike_count_by_visibility)"
      ],
      "metadata": {
        "id": "7e76aljH_yOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df1, x='Visibility (10m)', y='Rented Bike Count')\n",
        "plt.title(\"Visibility vs Rented Bike Count\")\n",
        "plt.xlabel(\"Visibility\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The scatter plot shows the relationship between visibility and rented bike count. The insights from the graph indicate that as visibility increases, the number of rented bikes generally increases. There is a noticeable clustering of higher bike rentals at higher visibility levels, particularly around 2000 meters. This suggests that better visibility conditions are associated with higher bike rental counts."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The gained insights from the scatter plot indicating a positive correlation between visibility and rented bike count can indeed help in creating a positive business impact for a bike rental company."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 : Is there any noticeable relationship between dew point temperature ('Dew point temperature(°C)') and rented bike count?\n"
      ],
      "metadata": {
        "id": "ynDtdhucBFfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relationship_between_dew_point_temperature_and_bike_rental = df1.groupby('Dew point temperature(°C)')['Rented Bike Count'].sum().reset_index()\n",
        "print(relationship_between_dew_point_temperature_and_bike_rental)"
      ],
      "metadata": {
        "id": "BgIL1unjBVVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df1, x='Dew point temperature(°C)', y='Rented Bike Count')\n",
        "plt.title(\"Dew point temperature vs Rented Bike Count\")\n",
        "plt.xlabel(\"Dew point temperature\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I used scatterplot because catterplots are used to visualize the relationship between two continuous variables, helping to identify patterns, trends, and correlations in the data at a glance."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : Yes, There is noticeable relationship between dew point temprature and rented bike count. When dew point temprature is maximum then the count of the rented bike is maximum and when temptarure is minimum then count is also minimum."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The observed relationship between dew point temperature and bike rental count suggests a positive impact for the business, as it allows for strategic planning and resource allocation based on weather conditions. However, overreliance on optimal weather conditions for high rental counts may lead to negative growth during periods of unfavorable weather, potentially resulting in revenue fluctuations and operational challenges."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 : How does the functioning day ('Functioning Day') affect bike rental demand?"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# group by functioning day and calculate the mean of bike rental demand.\n",
        "bike_rental_demand_by_functioning_day = df1.groupby('Functioning Day')['Rented Bike Count'].mean().reset_index()\n",
        "print(bike_rental_demand_by_functioning_day)"
      ],
      "metadata": {
        "id": "JjYYzo3jDr_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=bike_rental_demand_by_functioning_day, x='Functioning Day', y='Rented Bike Count', palette = 'deep')\n",
        "plt.title(\"Functioning Day vs Rented Bike Count\")\n",
        "plt.xlabel(\"Functioning Day\")\n",
        "plt.ylabel(\"Rented Bike Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The above barplot shows that on functioning day rented bike count is high and when there is no functioning day then the rented bike count is zero."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "jCtfBBAzFXWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude non-numeric columns from the DataFrame\n",
        "numeric_df = df1.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "swz7mhhSF568"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above heatmap we can have followinf indights:\n",
        "* Rented bike count has a strong positive correlation with temperature (0.54), meaning higher temperatures are associated with more bike rentals.\n",
        "\n",
        "* There is a moderate positive correlation between rented bike count and the time of day (hour) (0.39) as well as dew point temperature (0.39), indicating more rentals during specific hours and in higher dew point conditions.\n",
        "\n",
        "* Rented bike count is negatively correlated with humidity (-0.20) and visibility (-0.24), suggesting that higher humidity and lower visibility reduce bike rentals.\n",
        "\n",
        "* There are weak positive correlations with wind speed (0.10) and solar radiation (0.25), indicating these factors have minimal impact on rentals.\n",
        "\n",
        "* Both rainfall (-0.14) and snowfall (-0.11) have weak negative correlations with rented bike count, suggesting that precipitation slightly reduces bike rentals."
      ],
      "metadata": {
        "id": "_3-qWWndGcjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "H9OY--FqIrsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The pair plot provides a comprehensive view of the relationships between multiple variables. Key insights include:\n",
        "\n",
        "1. **Temperature vs. Rented Bike Count**: There is a clear positive trend showing higher bike rentals at higher temperatures, confirming the strong correlation observed earlier.\n",
        "\n",
        "2. **Hour vs. Rented Bike Count**: The plot shows that bike rentals have a distinct pattern across different hours, likely peaking during specific times of the day, such as morning and evening commutes.\n",
        "\n",
        "3. **Humidity vs. Rented Bike Count**: The scatter plot reveals a weak negative trend, indicating that higher humidity tends to reduce bike rentals.\n",
        "\n",
        "4. **Dew Point Temperature vs. Temperature**: There is a strong positive linear relationship between dew point temperature and temperature, indicating that as the temperature increases, the dew point temperature also rises.\n",
        "\n",
        "5. **Rainfall and Snowfall**: Both these variables show a sparse distribution with rented bike count, indicating they have less frequent but notable negative impacts on bike rentals.\n",
        "\n",
        "6. **Wind Speed, Visibility, and Solar Radiation**: These factors show weak to moderate relationships with rented bike count. Solar radiation has a slightly positive impact, while visibility and wind speed show no strong patterns.\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer :\n",
        "\n",
        "* Null Hypothesis (H0): There is no significant difference in bike rental demand across different temperature ranges.\n",
        "\n",
        "* Alternative Hypothesis (H1): Bike rental demand significantly varies across different temperature ranges, with a peak in demand observed in mild to warm weather conditions (20-25°C)."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the dataset into two groups based on temperature\n",
        "group1 = df1[df1['Temperature(°C)'] < 20]['Rented Bike Count']\n",
        "group2 = df1[df1['Temperature(°C)'] >= 20]['Rented Bike Count']\n",
        "\n",
        "# Perform t-test\n",
        "t_statistic, p_value = stats.ttest_ind(group1, group2)\n",
        "\n",
        "# Print the results\n",
        "print(\"T-Statistic:\", t_statistic)\n",
        "print(\"P-Value:\", p_value)"
      ],
      "metadata": {
        "id": "nuzwWmUr8C_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The extremely large negative T-Statistic (-47.5046) and the P-Value of 0.0 suggest a highly significant difference in bike rental counts between temperatures below 20°C and those 20°C and above, indicating temperature has a very strong effect on bike rentals."
      ],
      "metadata": {
        "id": "BuoNAg0T8na9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I used T-Statistical test to calculate P-Value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The t-statistical test is used to determine if there is a significant difference between the means of two groups, which helps in understanding whether a particular factor (like temperature) has a substantial impact on the observed data."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer :\n",
        "* Null Hypothesis (H0): There is no significance difference in bike rental counts across diffrent seasons.\n",
        "\n",
        "* Alternative Hypothesis (H1) : There is a significant difference in bike rental counts across different seasons."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Group data by seasons\n",
        "data = [df1[df1['Seasons'] == season]['Rented Bike Count'] for season in df1['Seasons'].unique()]\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = stats.f_oneway(*data)\n",
        "\n",
        "# Print the results\n",
        "print(\"F-Statistic:\", f_statistic)\n",
        "print(\"P-Value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above value indicates that a highly significant diffrence in bike rental counts across the diffrent seasons. The extremely low P-Value suggests that the likelihood observing such a large F-Statistic under the null hypothesis (that there is no difference in bike rental counts across seasons) is extremely low. Therefore, we reject the null hypothesis and conclude that the bike rental counts vary significantly between seasons."
      ],
      "metadata": {
        "id": "Cgg9kVCiAULg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I used F_statistical test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The F-statistical method (ANOVA) is used to determine if there are significant differences between the means of multiple groups, making it ideal for comparing bike rental counts across different seasons."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer :\n",
        "\n",
        "* Null Hypothesis (H0): There is no significant difference in bike rental counts between days with and without holidays.\n",
        "\n",
        "* Alternative Hypothesis (H1): There is a significant difference in bike rental counts between days with and without holidays."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Divide the dataset into two groups based on holiday\n",
        "holiday_group = df1[df1['Holiday'] == 'Holiday']['Rented Bike Count']\n",
        "non_holiday_group = df1[df1['Holiday'] == 'No Holiday']['Rented Bike Count']\n",
        "\n",
        "# Perform t-test\n",
        "t_statistic, p_value = ttest_ind(holiday_group, non_holiday_group)\n",
        "\n",
        "# Print the results\n",
        "print(\"T-Statistic:\", t_statistic)\n",
        "print(\"P-Value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The T-Statistic of -6.7874 and the very small P-Value (1.21)suggest that there is a highly significant difference in bike rental counts between days with and without holidays.\n",
        "\n"
      ],
      "metadata": {
        "id": "9gTQCHiNCFDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I have used T-Statistical test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : The t-test is used to determine if there is a significant difference between the means of two groups. In this scenario, we're comparing bike rental counts between days with and without holidays, which are two distinct groups. Therefore, the t-test is appropriate for examining whether there's a statistically significant difference in bike rental counts between these two conditions."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# missing values\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "hr4s3RpwI24B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : There is no any missing values in the given dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "outlier_columns = list(set(df1.describe().columns) - {'Rented Bike Count', 'Hour'})\n",
        "outlier_columns"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "for index, column in enumerate(outlier_columns):\n",
        "    plt.subplot(3, 3, index+1)\n",
        "    sns.boxplot(df1[column], orient='h')\n",
        "    plt.title(column)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_JczvvWxDcZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer  : From above boxplots we can see that 'snowfall','wind speed','solar radiation','rainfall' columns have outliers."
      ],
      "metadata": {
        "id": "VQ0EqQn4EpQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a list of columns that contains outliers\n",
        "outlier_cols = ['Rainfall(mm)','Wind speed (m/s)','Snowfall (cm)','Solar Radiation (MJ/m2)']\n",
        "\n",
        "#Finding the inter-quartile range for the columns with outliers\n",
        "Q1 = df1[outlier_cols].quantile(0.25)\n",
        "Q3 = df1[outlier_cols].quantile(0.75)\n",
        "IQR = Q3-Q1\n",
        "\n",
        "#Calculating the upper and lower fence for outlier removal\n",
        "u_fence = Q3 + (1.5*IQR)\n",
        "l_fence = Q1 - (1.5*IQR)\n",
        "\n",
        "#Detecting and removing the outliers\n",
        "df1[outlier_cols] = df1[outlier_cols][~((df1[outlier_cols] < l_fence) | (df1[outlier_cols] > u_fence))]"
      ],
      "metadata": {
        "id": "1QHJWYEjKcss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "sO1j7zDPKzPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After removing outliers, null values may arise due to the removal of certain data points. To handle these null values, replacing them with the median is a robust approach, as the median is less influenced by outliers compared to the mean."
      ],
      "metadata": {
        "id": "Ycl8FTEuMaON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute the null values created by outlier handeling\n",
        "def impute_null(outlier_cols):\n",
        "    for col in outlier_cols:\n",
        "        df1[col] = df1[col].fillna(df1[col].median())\n",
        "    return df1\n",
        "\n",
        "df1 = impute_null(outlier_cols)\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "ab3ypU98LS0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Categorical encoding is the process of converting categorical variables into numerical representations that can be used as inputs for machine learning algorithms.**\n",
        "\n",
        "**In above dataset seasons, holiday and functional day these columns have categorical values. Therefore these three columns require encoding.**"
      ],
      "metadata": {
        "id": "P1MRZJXDR1F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the seasons columns\n",
        "df1['Winter'] = np.where(df1['Seasons']=='Winter', 1, 0)\n",
        "df1['Spring'] = np.where(df1['Seasons']=='Spring', 1, 0)\n",
        "df1['Summer'] = np.where(df1['Seasons']=='Summer', 1, 0)\n",
        "df1['Autumn'] = np.where(df1['Seasons']=='Autumn', 1, 0)\n",
        "\n",
        "#Removing seasons column\n",
        "df1.drop(columns=['Seasons'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "zpK9I0klUUyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding holiday column\n",
        "holiday_mapping = {'Holiday': 1, 'No Holiday': 0}\n",
        "df1['Holiday'] = df1['Holiday'].map(holiday_mapping)"
      ],
      "metadata": {
        "id": "n8yhMTPqRlwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding functining day column\n",
        "functioning_day_mapping = {'Yes': 1, 'No': 0}\n",
        "df1['Functioning Day'] = df1['Functioning Day'].map(functioning_day_mapping)"
      ],
      "metadata": {
        "id": "BdUjhTr-SWbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "pR8E0M0sTyOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer :\n",
        "\n",
        "* For encoding seasons column One-Hot Encoding techmique is used. In one-hot encoding, each category is represented by a binary column where a 1 indicates the presence of that category and 0 indicates the absence. Each category in the 'Seasons' column ('Winter', 'Spring', 'Summer', 'Autumn') is encoded into a separate binary column, creating a sparse matrix representation of the categorical variable. This technique is commonly used when the categories are nominal (unordered) and do not have a natural ordinal relationship.\n",
        "\n",
        "* For encoding holiday column Label Encoding technique is used because abel encoding is employed here by assigning a binary representation to each category in the 'Holiday' column. 'Holiday' is mapped to 1, indicating the presence of a holiday, while 'No Holiday' is mapped to 0, indicating the absence of a holiday.\n",
        "\n",
        "* For encoding functioning column Label Encoding technique is used because label encoding is employed here by assigning a binary representation to each category in the 'Functioning Day' column. 'Yes' is mapped to 1, indicating a functioning day, while 'No' is mapped to 0, indicating a non-functioning day."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "LSn-AF0CX4PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unnecessary columns\n",
        "df1.drop(columns=['Date','Dew point temperature(°C)'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "BDvFWj21XnpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "Z2qev6h4e9Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking and Removing Multicollinearity**"
      ],
      "metadata": {
        "id": "XkR6012FcxTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity refers to the phenomenon where two or more predictor variables in a regression model are highly correlated with each other. It can lead to issues such as inflated standard errors of coefficients and difficulty in interpreting the effects of individual predictors on the target variable.\n",
        "\n",
        "Accepted multicollinearity is below 10."
      ],
      "metadata": {
        "id": "DodLtv_ujFdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of independent variable\n",
        "independent_variable = list(set(df1.columns) - {'Rented Bike Count'})\n",
        "independent_variable"
      ],
      "metadata": {
        "collapsed": true,
        "id": "K5YjDG53e1iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate variance inflation factor\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = independent_variable\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df1[independent_variable].values, i) for i in range(len(independent_variable))]\n",
        "print(vif_data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5bbWDHphfulT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observed that the predictor variables representing the seasons have very high VIF values, indicating strong multicollinearity. To address this, we will drop one of the season columns. We choose to drop the 'Winter' column because it corresponds to the season with the lowest bike rental count. Additionally, the columns 'Snowfall' and 'Rainfall' have negligible VIF values, suggesting they do not contribute to multicollinearity and can be dropped from the analysis."
      ],
      "metadata": {
        "id": "JV4RYgezgxXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop columns\n",
        "df1.drop(columns=['Winter','Snowfall (cm)','Rainfall(mm)'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "3e_v-v-RhqJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of remaining independent columns\n",
        "independent_variable1 = list(set(df1.columns) - {'Rented Bike Count'})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IxrNAEUThz8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = independent_variable1\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df1[independent_variable1].values, i) for i in range(len(independent_variable1))]\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "YqRT1YQch9Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that functioning column has VIF > 10 therefor drop Functioning day column"
      ],
      "metadata": {
        "id": "i7y_fz73iV2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop column\n",
        "df1.drop(columns=['Functioning Day'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "atsNxW6gig4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remaining independent columns\n",
        "independent_variable2 = list(set(df1.columns) - {'Rented Bike Count'})"
      ],
      "metadata": {
        "id": "VYG1aGJgioyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = independent_variable2\n",
        "vif_data['VIF'] = [variance_inflation_factor(df1[independent_variable2].values, i) for i in range(len(independent_variable2))]\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "njcoWNB0ikpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have all feature whoes multicollinearity is below 10."
      ],
      "metadata": {
        "id": "4iqMfnCnjyzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check correlation between independent and dependent variables"
      ],
      "metadata": {
        "id": "tW1yYaEIj-aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check correlation between independent_variables2 and dependent variable using regression plot\n",
        "for col in independent_variable2:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.regplot(x=col, y='Rented Bike Count', data=df1, scatter_kws={\"color\" : 'pink'}, line_kws={\"color\" : 'black'})\n",
        "    correlation = df1[col].corr(df1['Rented Bike Count'])\n",
        "    plt.title(f\"Correlation between {col} and Rented Bike Count: {correlation:.3f}\")\n",
        "    plt.ylabel('Rented Bike Count')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7YuDWGTEkIY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that all the independent variabale have linear correlation with the dependent variable."
      ],
      "metadata": {
        "id": "J291zbOBnMi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessin of the Data**"
      ],
      "metadata": {
        "id": "YEVepb4Snp9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataset independent variables and dependent variables\n",
        "X = df1.drop(columns=['Rented Bike Count'])\n",
        "y = df1['Rented Bike Count']"
      ],
      "metadata": {
        "id": "PH3L21axnz3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# independent variable dataset\n",
        "X.head()"
      ],
      "metadata": {
        "id": "Eg12oSyMoIUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dependent variable dataset\n",
        "y.head()"
      ],
      "metadata": {
        "id": "TylwQ12YoQDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Transformation"
      ],
      "metadata": {
        "id": "dPR2PzKZxfmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cheking distribution of targeted variable\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_oqPVhTfvEQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that in targetrd variable we observed distribution because of positively skewed distribution and we will normalize using squre root transformation."
      ],
      "metadata": {
        "id": "wSUaeM_Gzm9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use log trasformation\n",
        "y = np.sqrt(y)"
      ],
      "metadata": {
        "id": "RC4HJB720QeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot histplot\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N_Biikbg03q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the target variable is normalized."
      ],
      "metadata": {
        "id": "UX1wcHBq9MmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Apply test and train split**"
      ],
      "metadata": {
        "id": "RmFcMprs9ckh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split datasset into test and train datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zA_1gz_I9b-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of train dataset if the independent variable\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "sk3Kmo1W94x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # check the shape of test dataset if the independent variable\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "61N9X0QI-JWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Scalling:**\n",
        "\n",
        "Feature scaling involves changing the range or distribution of numerical features so that they have similar scales.\n",
        "\n",
        "### **Common methods include:**\n",
        "\n",
        "* **Standardization (Z-score normalization)**: Centers the data around zero with a standard deviation of one.\n",
        "* **Normalization (Min-Max scaling)**: Scales the data to a fixed range, typically [0, 1].\n",
        "* **Robust Scaling**: Uses the median and interquartile range, which makes it robust to outliers.\n",
        "\n",
        "Here we are going to use standerdisation method."
      ],
      "metadata": {
        "id": "lnhmDdQN-cCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standerdization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "mqEPkRED_A2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset after stabderdisation\n",
        "X_train"
      ],
      "metadata": {
        "id": "GxMzi2BK_S7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we are going to implement following regression models:\n",
        "\n",
        "1. Linear Regression\n",
        "2. Ridge Regression\n",
        "3. Lasso Regression\n",
        "4. Elastic Net Regression"
      ],
      "metadata": {
        "id": "-A4_XUC3_izx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 : Linear Regression:\n",
        "\n",
        "Linear regression is the simplest form of regression analysis where the relationship between the dependent variable y and one or more independent variables X is modeled by fitting a linear equation to the observed data."
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize linear regression model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "linear_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the score of model\n",
        "linear_model.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "nwC940bECILE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking coefficient value\n",
        "linear_model.coef_"
      ],
      "metadata": {
        "id": "JDK0MMcFCpKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the value of the dependent variable for train and test dataset\n",
        "y_train_pred_lr = linear_model.predict(X_train)\n",
        "y_test_pred_lr = linear_model.predict(X_test)\n",
        "print(y_train_pred_lr)\n",
        "print(y_test_pred_lr)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9iiNhvI8CzYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function to plot the comparison between actual values and predictions\n",
        "def plot_comparison(y_pred,model):\n",
        "   plt.figure(figsize=(8,4))\n",
        "   plt.title(\"The comparison of actual values and predictions obtained by \"+model)\n",
        "   plt.plot(np.array((y_test)))\n",
        "   plt.plot((y_pred),color='red')\n",
        "   plt.legend([\"Actual\",\"Predicted\"])\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "cleuTA0NRD9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the comparison between actual and predicted values obtained by Linear Regression\n",
        "plot_comparison(y_test_pred_lr,'Linear Regression')"
      ],
      "metadata": {
        "id": "twtUy_y4RGy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation matrix of the model\n",
        "print('MAE:', mean_absolute_error(y_test, y_test_pred_lr))\n",
        "print('MSE:', mean_squared_error(y_test, y_test_pred_lr))\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_test_pred_lr)))\n",
        "print('R2 Score:', r2_score(y_test, y_test_pred_lr))"
      ],
      "metadata": {
        "id": "bdhJQSaeCdpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metrics\n",
        "metrics = {\n",
        "    'MAE': 6.631991473282277,\n",
        "    'MSE': 81.09904863897937,\n",
        "    'RMSE': 9.005501020985971,\n",
        "    'R2 Score': 0.4730974203328704,\n",
        "}"
      ],
      "metadata": {
        "id": "MkIAzPCHJNag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Convert the dictionary to two lists\n",
        "metric_names = list(metrics.keys())\n",
        "metric_values = list(metrics.values())\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=metric_names, y=metric_values, palette='viridis')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Regression Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metrics')\n",
        "\n",
        "# Display the values on top of the bars\n",
        "for i, v in enumerate(metric_values):\n",
        "    plt.text(i, v + 0.05, f\"{v:.10f}\", ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can see that:\n",
        "* The Mean Absolute Error (MAE) of 6.63 indicates that, on average, your model's predictions are off by approximately 6.63 units from the actual values.\n",
        "* The Mean Squared Error (MSE) of 81.10 indicates that, on average, the squared differences between the predicted and actual values are 81.10, suggesting that the model's predictions have a considerable variance and the errors can be relatively large.\n",
        "* The RMSE (Root Mean Square Error) value of 9.005501020985971 indicates the average magnitude of the errors between the predicted values of your model and the actual observed values.\n",
        "* An R2 score of 0.473 suggests that approximately 47.3% of the variance in the dependent variable is explained by the independent variables in your model, indicating moderate predictive capability.\n",
        "\n",
        "In summary, the model's performance seems moderate based on the provided metrics, further evaluation is necessary to determine its adequacy for the dataset and whether improvements are needed."
      ],
      "metadata": {
        "id": "v5tEhKdhJkpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'n_jobs': [None, -1, 1, 2],\n",
        "    'copy_X':[True, False]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SvUTwYIsHpYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Output the best parameters and new metrics\n",
        "print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
        "print(\"MAE after tuning:\", mae)\n",
        "print(\"MSE after tuning:\", mse)\n",
        "print(\"RMSE after tuning:\", rmse)\n",
        "print(\"R2 Score after tuning:\", r2)"
      ],
      "metadata": {
        "id": "U3Ubk7aVIALY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I used GridSearchCV for hyperparameter optimization because it exhaustively searches through all possible combinations of specified parameters, ensuring the best set is found for the model. This thorough approach is beneficial for small to moderately sized parameter grids."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : No, There is no any improvement in evaluation metric score chart."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 : Ridge Regression\n",
        "\n",
        "Ridge regression is a type of linear regression that includes a regularization term to prevent overfitting. This regularization term, which is the sum of the squared coefficients multiplied by a penalty factor (alpha), shrinks the coefficients towards zero, adding bias but reducing variance and potentially improving model performance on new data."
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Ridge regression model\n",
        "ridge= Ridge()\n",
        "\n",
        "# Define the parameter grid for alpha\n",
        "param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "\n",
        "# Perform GridSearchCV to find the best alpha\n",
        "grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "si9ztfWuMiwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the best parameters for Ridge regression fetched through GridSearchCV\n",
        "print(f\"The best value for alpha in ridge regression through GridSearchCV is found to br {grid_search.best_params_}\")\n",
        "print(f\"\\nUsing {grid_search.best_params_} as the value for alpha gives a negative mean squared error of: {grid_search.best_score_}\")"
      ],
      "metadata": {
        "id": "8vaXKnRONiM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the Ridge regression model on the dataset with appropriate alpha value\n",
        "ridge_model=Ridge(alpha=10).fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "6snnikIFO0VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting values of the independent variable on the test set\n",
        "y_test_pred_ridge = ridge_model.predict(X_test)"
      ],
      "metadata": {
        "id": "xib8zGCxO9y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the comparison between actual and predicted values obtained by Ridge Regression\n",
        "plot_comparison(y_test_pred_ridge,'Ridge Regression')"
      ],
      "metadata": {
        "id": "jHLwAzuzRm24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for the Ridge regression model\n",
        "ridge_mae = mean_absolute_error(y_test, y_test_pred_ridge)\n",
        "ridge_mse = mean_squared_error(y_test, y_test_pred_ridge)\n",
        "ridge_rmse = ridge_mse ** 0.5\n",
        "ridge_r2 = r2_score(y_test, y_test_pred_ridge)\n",
        "\n",
        "print(\"\\nBest alpha from GridSearchCV:\", grid_search.best_params_['alpha'])\n",
        "print(\"\\nRidge Regression Metrics After Hyperparameter Tuning:\")\n",
        "print(f\"MAE: {ridge_mae}\")\n",
        "print(f\"MSE: {ridge_mse}\")\n",
        "print(f\"RMSE: {ridge_rmse}\")\n",
        "print(f\"R2 Score: {ridge_r2}\")"
      ],
      "metadata": {
        "id": "wsRFMCNyNXJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metrics\n",
        "metrics_1 = {\n",
        "    'MAE': 6.631908141849714,\n",
        "    'MSE': 81.10342522112052,\n",
        "    'RMSE': 9.00574401263552,\n",
        "    'R2 Score': 0.473068985567494,\n",
        "}"
      ],
      "metadata": {
        "id": "BJF0rquSTKO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Convert the dictionary to two lists\n",
        "metric_names = list(metrics_1.keys())\n",
        "metric_values = list(metrics_1.values())\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=metric_names, y=metric_values, palette='viridis')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Regression Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metrics')\n",
        "\n",
        "# Display the values on top of the bars\n",
        "for i, v in enumerate(metric_values):\n",
        "    plt.text(i, v + 0.05, f\"{v:.10f}\", ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lefONY0YTg5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 : Lasso Regression\n",
        "\n",
        "Lasso regression, or L1 regularization, is a linear regression technique that adds a penalty term to the loss function, constraining the absolute size of the coefficients. It encourages sparse models by shrinking coefficients to zero, effectively performing feature selection and providing interpretable models with fewer predictors."
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization of lasso regression\n",
        "lasso = Lasso()\n",
        "\n",
        "# Define the parameter grid for alpha\n",
        "param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "\n",
        "# Perform GridSearchCV to find the best alpha\n",
        "lasso_grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "lasso_grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the best parameters for Ridge regression fetched through GridSearchCV\n",
        "print(f\"The best value for alpha in ridge regression through GridSearchCV is found to br {lasso_grid_search.best_params_}\")\n",
        "print(f\"\\nUsing {lasso_grid_search.best_params_} as the value for alpha gives a negative mean squared error of: {lasso_grid_search.best_score_}\")"
      ],
      "metadata": {
        "id": "ihnVemUmWmEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the lasso regression model on the dataset with appropriate alpha value\n",
        "lasso_model=Lasso(alpha=0.01).fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "EeEqk2_nXRen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting values of the independent variable on the test set\n",
        "y_test_pred_lasso = lasso_model.predict(X_test)"
      ],
      "metadata": {
        "id": "at64bVFbXfZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the comparison between actual and predicted values obtained by Ridge Regression\n",
        "plot_comparison(y_test_pred_lasso,'Lasso Regression')"
      ],
      "metadata": {
        "id": "SfNK9fjBXq91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for the lasso regression model\n",
        "lasso_mae = mean_absolute_error(y_test, y_test_pred_lasso)\n",
        "lasso_mse = mean_squared_error(y_test, y_test_pred_lasso)\n",
        "lasso_rmse = ridge_mse ** 0.5\n",
        "lasso_r2 = r2_score(y_test, y_test_pred_lasso)\n",
        "\n",
        "print(\"\\nBest alpha from GridSearchCV:\", lasso_grid_search.best_params_['alpha'])\n",
        "print(\"\\nLasso Regression Metrics After Hyperparameter Tuning:\")\n",
        "print(f\"MAE: {lasso_mae}\")\n",
        "print(f\"MSE: {lasso_mse}\")\n",
        "print(f\"RMSE: {lasso_rmse}\")\n",
        "print(f\"R2 Score: {lasso_r2}\")"
      ],
      "metadata": {
        "id": "prTEydxWX6xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Define the metrics\n",
        "metrics_2 = {\n",
        "    'MAE': 6.630418122574132,\n",
        "    'MSE': 81.09393160547758,\n",
        "    'RMSE': 9.005216910517902,\n",
        "    'R2 Score': 0.4731306658295511,\n",
        "}"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Convert the dictionary to two lists\n",
        "metric_names = list(metrics_1.keys())\n",
        "metric_values = list(metrics_1.values())\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=metric_names, y=metric_values, palette='viridis')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Regression Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metrics')\n",
        "\n",
        "# Display the values on top of the bars\n",
        "for i, v in enumerate(metric_values):\n",
        "    plt.text(i, v + 0.05, f\"{v:.10f}\", ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wn--i3EOa6kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 : Elastic Net Regression\n",
        "\n",
        "Elastic Net Regression is a hybrid regularization technique that combines L1 (Lasso) and L2 (Ridge) penalties in the loss function. It balances between feature selection (Lasso) and coefficient shrinkage (Ridge), providing a solution for multicollinearity and improving model performance by handling both high-dimensional data and correlated predictors."
      ],
      "metadata": {
        "id": "HqNSSBuCbQ8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize elastic net regression\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "\n",
        "# Fit the model on the training data\n",
        "elastic_net.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xmXHPAjLbLuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the score\n",
        "elastic_net.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "dc9g-56geMTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on the test set\n",
        "y_test_pred_elastic_net = elastic_net.predict(X_test)\n",
        "y_test_pred_elastic_net"
      ],
      "metadata": {
        "id": "nxlPCdljfQX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the comparison between actual and predicted values obtained by Ridge Regression\n",
        "plot_comparison(y_test_pred_elastic_net,'Elastic Net Regression')"
      ],
      "metadata": {
        "id": "u62ud8DBg6Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation matrics\n",
        "elastic_mae = mean_absolute_error(y_test, y_test_pred_elastic_net)\n",
        "elastic_mse = mean_squared_error(y_test, y_test_pred_elastic_net)\n",
        "elastic_rmse = ridge_mse ** 0.5\n",
        "elastic_r2 = r2_score(y_test, y_test_pred_elastic_net)\n",
        "\n",
        "print(f\"MAE: {elastic_mae}\")\n",
        "print(f\"MSE: {elastic_mse}\")\n",
        "print(f\"RMSE: {elastic_rmse}\")\n",
        "print(f\"R2 Score: {elastic_r2}\")"
      ],
      "metadata": {
        "id": "xIJJdIHJfe_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "matrices = {\n",
        "    'MAE': elastic_mae,\n",
        "    'MSE': elastic_mse,\n",
        "    'RMSE': elastic_rmse,\n",
        "    'R2 Score': elastic_r2\n",
        "}\n",
        "\n",
        "# plot the barplot\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.barplot(x=list(matrices.keys()), y=list(matrices.values()), palette='viridis')\n",
        "# Display the values on top of the bars\n",
        "for i, v in enumerate(metric_values):\n",
        "    plt.text(i, v + 0.05, f\"{v:.10f}\", ha='center', va='bottom')\n",
        "\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Regression Model Performance Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Metrics')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2wzzCBhjgSqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dictionaries for each model's metrics\n",
        "linear_regression_metrics = {\n",
        "    'Model': 'Linear Regression',\n",
        "    'MAE': 6.631991473282277,\n",
        "    'MSE': 81.09904863897937,\n",
        "    'RMSE': 9.005501020985971,\n",
        "    'R2 Score': 0.4730974203328704\n",
        "}\n",
        "\n",
        "ridge_regression_metrics = {\n",
        "    'Model': 'Ridge Regression',\n",
        "    'MAE': 6.631908141849714,\n",
        "    'MSE': 81.10342522112052,\n",
        "    'RMSE': 9.00574401263552,\n",
        "    'R2 Score': 0.473068985567494\n",
        "}\n",
        "\n",
        "lasso_regression_metrics = {\n",
        "    'Model': 'Lasso Regression',\n",
        "    'MAE': 6.630418122574132,\n",
        "    'MSE': 81.09393160547758,\n",
        "    'RMSE': 9.005216910517902,\n",
        "    'R2 Score': 0.4731306658295511\n",
        "}\n",
        "\n",
        "elastic_net_regression_metrics = {\n",
        "    'Model': 'Elastic Net Regression',\n",
        "    'MAE': 6.6717984977445175,\n",
        "    'MSE': 81.62135825952943,\n",
        "    'RMSE': 9.005216910517902,\n",
        "    'R2 Score': 0.46970396145670157\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "metrics_df = pd.DataFrame([linear_regression_metrics, ridge_regression_metrics, lasso_regression_metrics, elastic_net_regression_metrics])\n",
        "\n",
        "# Print the DataFrame\n",
        "print(metrics_df)"
      ],
      "metadata": {
        "id": "Kee26DS6jYas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on these metrics:\n",
        "\n",
        "* Linear Regression, Ridge Regression, and Lasso Regression have very similar performance across all metrics.\n",
        "* Elastic Net Regression performs slightly worse compared to the other models, with a higher MAE, MSE, and lower R2 Score.\n",
        "\n",
        "Considering the similarity in performance between Linear Regression, Ridge Regression, and Lasso Regression, either of these models can be considered the best choice for this dataset. However, Elastic Net Regression may not be the preferred choice in this case due to slightly poorer performance."
      ],
      "metadata": {
        "id": "jD6PygvkkaMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Explainability**"
      ],
      "metadata": {
        "id": "OE4GDA03_3i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shap_summary(model):\n",
        "    # Get X_train and X_columns from the global environment\n",
        "    global X_train, X_columns\n",
        "\n",
        "    # Create a Shap explainer\n",
        "    explainer_shap = shap.Explainer(model=model, masker=X_train)\n",
        "\n",
        "    # Calculate Shap values\n",
        "    shap_values = explainer_shap.shap_values(X_train)\n",
        "\n",
        "    # Set color palette\n",
        "    colors = [\"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#6d904f\", \"#8b8b8b\"]\n",
        "\n",
        "    # Plot the summary plot\n",
        "    shap.summary_plot(shap_values, X_train, feature_names=X.columns, plot_type=\"bar\", color=colors)"
      ],
      "metadata": {
        "id": "QxvtLdMysnb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for linear regression\n",
        "shap_summary(linear_model)"
      ],
      "metadata": {
        "id": "p9TP3QMUom6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for ridge regression\n",
        "shap_summary(ridge_model)"
      ],
      "metadata": {
        "id": "xPoN7dlvs0di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for lasso regression\n",
        "shap_summary(lasso_model)"
      ],
      "metadata": {
        "id": "LCvcVixZtO5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting shap summary plot for elastic net regression\n",
        "shap_summary(elastic_net)"
      ],
      "metadata": {
        "id": "Pst7HqqAtV4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "qLT3cUSMmJ83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Summary of the EDA :\n",
        "\n",
        "  * There's a rise in bike rentals during 2018 compared to 2017, with noticeable drops in rentals during 2017, suggesting increased popularity or intensified marketing efforts from early 2018 onwards.\n",
        "\n",
        "  * Bike rental demand is high in warm weather condition and low in mild condition.\n",
        "  * The rented bike count is highest in the summer season, followed by autumn and then spring. The rented bike count is lowest in the winter season.\n",
        "\n",
        "  * when the wind speed is low then the rented bike count is hight and when wind speed is maximum then the bike count is less.\n",
        "\n",
        "  * When there is a holiday then the bike count is very less and when there is no holiday then the rent bike count is very high.\n",
        "\n",
        "  * Better visibility conditions are associated with higher bike rental counts.\n",
        "\n",
        "  * When dew point temperature is maximum then the count of the rented bike is maximum and when temperature is minimum then count is also minimum.\n",
        "\n",
        "  * On a functioning day the rent bike count is high and when there is no functioning day then the rented bike count is zero.\n",
        "\n",
        "  * Rented bike count has a strong positive correlation with temperature (0.54), meaning higher temperatures are associated with more bike rentals.\n",
        "\n",
        "2.Summary of the Machine Learning Model applications :\n",
        "\n",
        "  * Based on these metrics:\n",
        "\n",
        "    * Linear Regression, Ridge Regression, and Lasso Regression have very similar performance across all metrics.\n",
        "\n",
        "    * Elastic Net Regression performs slightly worse compared to the other models, with a higher MAE, MSE, and lower R2 Score.\n",
        "\n",
        "    * Considering the similarity in performance between Linear Regression, Ridge Regression, and Lasso Regression, either of these models can be considered the best choice for this dataset. However, Elastic Net Regression may not be the preferred choice in this case due to slightly poorer performance.\n",
        "\n",
        "    * All 4 models have been explained with the help of SHAP library.\n",
        "\n",
        "    * Temperature and Hour are the two most important factors according to all the models.\n",
        "\n",
        "3. Cornerstone points of the process:\n",
        "\n",
        "  * Handling outliers to avoid their impact on predictions.\n",
        "  * Converting categorical variables into numerical representations.\n",
        "  * Managing multicollinearity among predictor variables.\n",
        "  * Choosing an easy-to-understand technique to explain model predictions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xubhiF2zmOMX"
      }
    }
  ]
}